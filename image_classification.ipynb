{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc847d7d-2a3f-46a1-8827-bad128c131f7",
   "metadata": {
    "id": "dc847d7d-2a3f-46a1-8827-bad128c131f7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b28d66",
   "metadata": {
    "id": "b9b28d66"
   },
   "source": [
    "## Importing CIFAR-10 DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ei6-szQPmQjc",
   "metadata": {
    "id": "ei6-szQPmQjc"
   },
   "source": [
    "We import CIFAR-10 data as tensors using torchvision dataset, normalize it, and load it into a DataLoader with a batch size of 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fe22a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "331fe22a",
    "outputId": "5c7b5371-64c6-48c3-db90-1d9d1836d054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:03<00:00, 42798541.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader= torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d435806",
   "metadata": {
    "id": "0d435806"
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ekX3bRm4qoWg",
   "metadata": {
    "id": "ekX3bRm4qoWg"
   },
   "source": [
    "We define a convolutional neural network (CNN) architecture. The architecture consists of two convolutional layers followed by three fully connected layers. The model utilizes max pooling and ReLU activation functions to extract features from input images and outputs predictions for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7824c047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7824c047",
    "outputId": "acc35759-d279-4df6-d682-cd9f9fe3329e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # input channels=3, output channels=6, kernel size=5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # input channels=6, output channels=16, kernel size=5x5\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(400, 120)  # input size=400, output size=120\n",
    "        self.fc2 = nn.Linear(120, 84)  # input size=120, output size=84\n",
    "        self.fc3 = nn.Linear(84, 10)  # input size=84, output size=10-> number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First convolutional layer with max pooling of size 2x2 and ReLU activation\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "\n",
    "        # Second convolutional layer with max pooling of size 2x2 and ReLU activation\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)  # Flatten feature maps\n",
    "\n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Final fully connected layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36da1cb",
   "metadata": {
    "id": "a36da1cb"
   },
   "outputs": [],
   "source": [
    "# Using Cross entropy loss as loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Using Adam with learning rate 0.01 for gradient descent\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QQyaiP6eo36G",
   "metadata": {
    "id": "QQyaiP6eo36G"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net=net.to(device) # Move the model to the available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74879273",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74879273",
    "outputId": "a9655013-3b5f-4fea-b5d0-e115250fdc82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 1.766820\n",
      "Epoch: 1 \tTraining Loss: 1.617495\n",
      "Epoch: 2 \tTraining Loss: 1.575118\n",
      "Epoch: 3 \tTraining Loss: 1.546802\n",
      "Epoch: 4 \tTraining Loss: 1.527485\n",
      "Epoch: 5 \tTraining Loss: 1.512298\n",
      "Epoch: 6 \tTraining Loss: 1.488030\n",
      "Epoch: 7 \tTraining Loss: 1.464262\n",
      "Epoch: 8 \tTraining Loss: 1.459357\n",
      "Epoch: 9 \tTraining Loss: 1.442765\n",
      "Epoch: 10 \tTraining Loss: 1.424231\n",
      "Epoch: 11 \tTraining Loss: 1.409670\n",
      "Epoch: 12 \tTraining Loss: 1.415659\n",
      "Epoch: 13 \tTraining Loss: 1.406955\n",
      "Epoch: 14 \tTraining Loss: 1.402304\n",
      "Epoch: 15 \tTraining Loss: 1.384663\n",
      "Epoch: 16 \tTraining Loss: 1.378980\n",
      "Epoch: 17 \tTraining Loss: 1.361006\n",
      "Epoch: 18 \tTraining Loss: 1.355067\n",
      "Epoch: 19 \tTraining Loss: 1.355414\n",
      "Epoch: 20 \tTraining Loss: 1.335979\n",
      "Epoch: 21 \tTraining Loss: 1.345602\n",
      "Epoch: 22 \tTraining Loss: 1.334667\n",
      "Epoch: 23 \tTraining Loss: 1.322590\n",
      "Epoch: 24 \tTraining Loss: 1.306889\n",
      "Epoch: 25 \tTraining Loss: 1.324198\n",
      "Epoch: 26 \tTraining Loss: 1.294480\n",
      "Epoch: 27 \tTraining Loss: 1.323995\n",
      "Epoch: 28 \tTraining Loss: 1.306020\n",
      "Epoch: 29 \tTraining Loss: 1.282967\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(30):\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Iterate over batches of data in the training loader\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the avaiable device (cuda or cpu)\n",
    "        optimizer.zero_grad()   # Zero the gradient buffers\n",
    "        output = net(data)  # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        train_loss += loss.item() * data.size(0)  # Accumulate the training loss\n",
    "\n",
    "    train_loss = train_loss / len(trainloader.dataset)  # Calculate average training loss per sample\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa53f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5fa53f7",
    "outputId": "f756bef7-5f36-401e-871d-f7f6ad719fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 51.51%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training set\n",
    "correct = 0\n",
    "total = 0\n",
    "# Set the model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the selected device\n",
    "        # Perform forward pass\n",
    "        outputs = net(data)\n",
    "        # Get the predicted classes\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        # Update total number of samples\n",
    "        total += target.size(0)\n",
    "        # Update number of correct predictions\n",
    "        correct += (pred == target).sum()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = float(100 * correct / total)\n",
    "\n",
    "print(f'Test accuracy is: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rpVPkYOGq1AM",
   "metadata": {
    "id": "rpVPkYOGq1AM"
   },
   "source": [
    "\n",
    "With the basic model architecture defined, we achieved an accuracy of 51.5% on the dataset. In the next steps, we will explore enhancements to the model architecture to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd1026",
   "metadata": {
    "id": "b6fd1026"
   },
   "source": [
    "## Improved CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i8lCXalitfxM",
   "metadata": {
    "id": "i8lCXalitfxM"
   },
   "source": [
    "We enhance the architecture by defining a convolutional neural network, featuring batch normalization after each convolutional layer. The architecture comprises three convolutional layers with subsequent max pooling operations. Concluding with three fully connected layers with ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8620b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e8620b4",
    "outputId": "8300d2b7-b158-4541-a92a-7dbf43e97988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)  # Batch normalization after conv1\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)  # Batch normalization after conv2\n",
    "\n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(512, 256)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(256, 128)  # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(128, 10)   # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First conv layer with max-pooling of 2x2 and stride 2, with batch normalization and ReLU activation\n",
    "        x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), 2)\n",
    "        # Second conv layer with max-pooling of 2x2 and stride 2, with batch normalization and ReLU activation\n",
    "        x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)\n",
    "        # Forward pass through conv3 with ReLU activation\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        # Flatten the output tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Forward pass through fully connected layers with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Final output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net2 = Net2()\n",
    "print(net2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d6b4d",
   "metadata": {
    "id": "462d6b4d"
   },
   "outputs": [],
   "source": [
    "# Using Cross entropy loss as loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Using Adam with learning rate 0.01 for gradient descent\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tn-wHyL6vcY_",
   "metadata": {
    "id": "Tn-wHyL6vcY_"
   },
   "outputs": [],
   "source": [
    "net2=net2.to(device) # Move the model to the available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92379c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92379c3e",
    "outputId": "6aab07dc-d514-4390-beb8-62f2953ffaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 1.769236\n",
      "Epoch: 1 \tTraining Loss: 1.501370\n",
      "Epoch: 2 \tTraining Loss: 1.421908\n",
      "Epoch: 3 \tTraining Loss: 1.377169\n",
      "Epoch: 4 \tTraining Loss: 1.344728\n",
      "Epoch: 5 \tTraining Loss: 1.314730\n",
      "Epoch: 6 \tTraining Loss: 1.285381\n",
      "Epoch: 7 \tTraining Loss: 1.257727\n",
      "Epoch: 8 \tTraining Loss: 1.243471\n",
      "Epoch: 9 \tTraining Loss: 1.225556\n",
      "Epoch: 10 \tTraining Loss: 1.212813\n",
      "Epoch: 11 \tTraining Loss: 1.178521\n",
      "Epoch: 12 \tTraining Loss: 1.147031\n",
      "Epoch: 13 \tTraining Loss: 1.130814\n",
      "Epoch: 14 \tTraining Loss: 1.108860\n",
      "Epoch: 15 \tTraining Loss: 1.085133\n",
      "Epoch: 16 \tTraining Loss: 1.075097\n",
      "Epoch: 17 \tTraining Loss: 1.058152\n",
      "Epoch: 18 \tTraining Loss: 1.048248\n",
      "Epoch: 19 \tTraining Loss: 1.032190\n",
      "Epoch: 20 \tTraining Loss: 1.018758\n",
      "Epoch: 21 \tTraining Loss: 1.004898\n",
      "Epoch: 22 \tTraining Loss: 0.995754\n",
      "Epoch: 23 \tTraining Loss: 0.986801\n",
      "Epoch: 24 \tTraining Loss: 0.974117\n",
      "Epoch: 25 \tTraining Loss: 0.968210\n",
      "Epoch: 26 \tTraining Loss: 0.961463\n",
      "Epoch: 27 \tTraining Loss: 0.956993\n",
      "Epoch: 28 \tTraining Loss: 0.951371\n",
      "Epoch: 29 \tTraining Loss: 0.940995\n"
     ]
    }
   ],
   "source": [
    "# Training the model for 30 epochs, batch size of 64\n",
    "for epoch in range(30):\n",
    "    train_loss = 0.0\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net2(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159782",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55159782",
    "outputId": "d90d8ed1-07bb-4dd9-bcfc-9734e1038480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 62.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training set\n",
    "correct = 0\n",
    "total = 0\n",
    "net2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = net2(data)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (pred == target).sum()\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = float(100 * correct / total)\n",
    "print(f'Test accuracy is: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dPYiE4CmxbwM",
   "metadata": {
    "id": "dPYiE4CmxbwM"
   },
   "source": [
    "Here we see that by increasing the depth of the Conv Net and adding batch Norm, we improved the model's performance, achieving an acuuracy of 62.5% on the test set. Further improvements, like adjusting the learning rate in Adam optimization, are possible, but we're holding off due to limited computing resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6d636",
   "metadata": {
    "id": "8cb6d636"
   },
   "source": [
    "## Transfer Learning using ResNet-18 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XZjHSWZazefm",
   "metadata": {
    "id": "XZjHSWZazefm"
   },
   "source": [
    "We will now implement transfer learning using the PyTorch ResNet-18 model on the CIFAR-10 dataset. We will freeze all weights except for the last FC layer, which will be trained specifically for the 10 classes in CIFAR-10. Prior to using ResNet, we need to resize our CIFAR-10 dataset to the size of 224x224 and normalize it using the mean values `[0.485, 0.456, 0.406]` and standard deviation values `[0.229, 0.224, 0.225]`, as specified in the [ResNet](https://pytorch.org/hub/pytorch_vision_resnet/) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c22411d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c22411d",
    "outputId": "25590d46-d13b-4cf2-8906-fe6bd09d0a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:13<00:00, 12984547.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform2 = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset2 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform2)\n",
    "trainloader2 = torch.utils.data.DataLoader(trainset2, batch_size=64,shuffle=True)\n",
    "testset2 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform2)\n",
    "testloader2 = torch.utils.data.DataLoader(testset2, batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e033a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e033a79",
    "outputId": "b89597bf-a036-4fbf-9cef-53771932f30a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model_resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
    "# Print ResNet-18 model\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2-zWmdRp2JYK",
   "metadata": {
    "id": "2-zWmdRp2JYK"
   },
   "source": [
    "Now, we freeze all ResNet parameters except the last fully connected layer and replace it with a fully connected layers for CIFAR-10 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Gwq0vPmR02OA",
   "metadata": {
    "id": "Gwq0vPmR02OA"
   },
   "outputs": [],
   "source": [
    "# Freeze all parameters in the ResNet model\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "# Get the number of input features for the last FC layer\n",
    "features = model_resnet.fc.in_features\n",
    "\n",
    "# Replace the last FC layer\n",
    "model_resnet.fc = nn.Sequential(nn.Linear(features, 128))  # Fully connected layer with 10 output features\n",
    "# New layers to a pre-trained model are by default set to require gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb488abd",
   "metadata": {
    "id": "cb488abd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnet = model_resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IcUJK7gV3I7z",
   "metadata": {
    "id": "IcUJK7gV3I7z"
   },
   "source": [
    "We will now train our ResNet model with the added fully connected layers for CIFAR-10 classification, while keeping the pre-existing layers frozen to leverage the pre-trained features. The model will take ~20 minutes if trained on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8742710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8742710",
    "outputId": "07449df5-a7d5-404f-f154-1c2f33225023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.814544\n",
      "Epoch: 1 \tTraining Loss: 0.812994\n",
      "Epoch: 2 \tTraining Loss: 0.842185\n",
      "Epoch: 3 \tTraining Loss: 0.814556\n",
      "Epoch: 4 \tTraining Loss: 0.814977\n",
      "Epoch: 5 \tTraining Loss: 0.820009\n",
      "Epoch: 6 \tTraining Loss: 0.821935\n",
      "Epoch: 7 \tTraining Loss: 0.818554\n",
      "Epoch: 8 \tTraining Loss: 0.822071\n",
      "Epoch: 9 \tTraining Loss: 0.846803\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = 0.0\n",
    "    for data, target in trainloader2:\n",
    "        data, target= data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_resnet(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(trainloader2.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8ZrrYEs3DEL",
   "metadata": {
    "id": "s8ZrrYEs3DEL"
   },
   "source": [
    "We now evaluate the ResNet model, which includes the added fully connected layers for CIFAR-10 classification, on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a24868",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62a24868",
    "outputId": "c6ad46a7-f944-4515-fbf8-fe9007bfcaf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 77.96%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model_resnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in testloader2:\n",
    "        data, labels= data.to(device), labels.to(device)\n",
    "        outputs = model_resnet(data)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum()\n",
    "\n",
    "accuracy = float(100 * correct / total)\n",
    "print(f'Test accuracy is: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5P5OEcYT3wnk",
   "metadata": {
    "id": "5P5OEcYT3wnk"
   },
   "source": [
    "After testing, our ResNet model performed better on the test set, achieving a 77.9% accuracy. We achieved improvements compared to our previous CNN model by leveraging pre-trained ResNet features and fine-tuning the model's parameters for last layer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
